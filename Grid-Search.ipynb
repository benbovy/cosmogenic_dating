{
 "metadata": {
  "name": "",
  "signature": "sha256:d99515f89f4fa5eb2208fea65dc92d1aac2a795811356ed5a87e61a8ef585735"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementation of MLE and the Bayesian approach using the Grid Search method"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A few functions and classes for applying the Maximum Likelihood Estimation and the Bayesian approach using the Grid Search method (i.e., uniform sampling of the parameter space).\n",
      "\n",
      "For more info about these methods, see the notebook [Inference_Notes](Inference_Notes.ipynb).\n",
      "\n",
      "The following code is saved as the Python module `gridsearch` so that it can be re-used in other notebooks. \n",
      "\n",
      "**CAUTION**: This implementation store all grid values in RAM. High resolution grid may consume a huge amount of memory!! Other solutions may greatly reduce the memory used (e.g., brute force implemented in the Scipy's optimize package: [brute](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brute.html#scipy.optimize.brute)) \n",
      "\n",
      "Author: B. Bovy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import csv\n",
      "import math\n",
      "\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "import pandas as pd\n",
      "import yaml\n",
      "\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "#sns.set(font=\"Liberation Sans\")'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile gridsearch.py\n",
      "\n",
      "\"\"\"\n",
      "An implementation of MLE and the Bayesian approach using the Grid-Search method.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import math\n",
      "import inspect\n",
      "from collections import OrderedDict\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "\n",
      "\n",
      "def chi2(mprofile, oprofile, ostd):\n",
      "    \"\"\"\n",
      "    Compute the chi-square given a measured\n",
      "    concentration profile (with known measurement\n",
      "    error) and predicted profile(s).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mprofile : 1-d or n-d array_like\n",
      "        the modelled concentration profile\n",
      "    oprofile : 1-d array_like\n",
      "        the measured concentration profile\n",
      "    ostd : 1-d array_like\n",
      "        the standard deviation values associated\n",
      "        to each profile measurements\n",
      "    \n",
      "    \"\"\"\n",
      "    return np.sum(np.power(oprofile - mprofile, 2) /\n",
      "                  np.power(ostd, 2),\n",
      "                  axis=0)\n",
      "\n",
      "    \n",
      "def likelihood(mprofile, oprofile, ostd, log=True):\n",
      "    \"\"\"\n",
      "    Compute the (log)likelihood function\n",
      "    given a measured concentration profile\n",
      "    (with known measurement error) and predicted\n",
      "    profile(s).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mprofile : 1-d or n-d array_like\n",
      "        the modelled concentration profile\n",
      "    oprofile : 1-d array_like\n",
      "        the measured concentration profile\n",
      "    ostd : 1-d array_like\n",
      "        the standard deviation values associated\n",
      "        to each profile measurements\n",
      "    log : bool\n",
      "         if True, returns the log likelihood\n",
      "\n",
      "    \"\"\"\n",
      "    std_square = np.power(ostd, 2)\n",
      "    \n",
      "    loglike = -0.5 * (\n",
      "        np.sum(np.power(oprofile - mprofile, 2)\n",
      "               / std_square\n",
      "               - np.log(2 * np.pi * std_square),\n",
      "               axis=0)\n",
      "    )\n",
      "    \n",
      "    if log:\n",
      "        return loglike\n",
      "    else:\n",
      "        return np.exp(loglike) \n",
      "\n",
      "\n",
      "def ppd(likelihood, prior, log=True):\n",
      "    \"\"\"\n",
      "    Compute the (non-normalized) (log)posterior\n",
      "    probability distribution given the (log)likelihood\n",
      "    and the (log)prior probability distribution.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    likelihood : float or array_like\n",
      "        the (log)likelihood function\n",
      "    prior : float or array_like\n",
      "        the (log)prior probability distribution\n",
      "    log : bool\n",
      "         Must be True if log-likelihood and\n",
      "         log-prior are given\n",
      "    \n",
      "    \"\"\"\n",
      "    if log:\n",
      "        return prior + likelihood\n",
      "    else:\n",
      "        return prior * likelihood\n",
      "\n",
      "\n",
      "def create_regular_grid(*ranges):\n",
      "    \"\"\"\n",
      "    Returns a regular grid for uniform sampling\n",
      "    in the multidimensional parameter space.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *ranges : range, range, ...\n",
      "        parameters ranges.\n",
      "        \n",
      "        range can be either a `slice` object \n",
      "        or a (start, end, step) 3-tuple.\n",
      "        if a complex number is be given as step,\n",
      "        its real part will be then interpreted as\n",
      "        the number of points to sample within the\n",
      "        range.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    [n-d array, n-d array, ...]\n",
      "        an array of grid coordinates for each parameter.\n",
      "        all arrays can be broadcasted to the regular\n",
      "        grid formed by all parameters.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    :func:`numpy.ogrid`\n",
      "\n",
      "    \"\"\"\n",
      "    p_slices = [r if type(r) is slice else slice(*r)\n",
      "                for r in ranges]\n",
      "    \n",
      "    return np.ogrid[p_slices]\n",
      "\n",
      "\n",
      "def integrate_over_grid(grid_step, F, axis=None):\n",
      "    \"\"\"\n",
      "    Integrate a function over a regular grid.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    grid_step : 1-d array_like\n",
      "        the resolution (step length) of one\n",
      "        (`axis`) or each (`axis=None`)\n",
      "        dimension of the regular grid\n",
      "    F : array_like\n",
      "        values of any function to integrate that \n",
      "        have been evaluated on the nodes of the\n",
      "        regular grid\n",
      "    axis : int or None\n",
      "        if None, integrate over the entire grid,\n",
      "        otherwise integrate only over the\n",
      "        specified axis\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    float or n-d array\n",
      "        depending on `axis`, one or several\n",
      "        integrals\n",
      "    \n",
      "    \"\"\"\n",
      "    if axis is None:\n",
      "        V = np.prod(grid_step)\n",
      "    else:\n",
      "        V = grid_step\n",
      "    \n",
      "    return V * np.sum(F, axis=axis)\n",
      "\n",
      "\n",
      "def normalize_ppd(ppd, grid_steps):\n",
      "    \"\"\"\n",
      "    Normalize the PPD values given on\n",
      "    a regular grid, so that the integral\n",
      "    over the grid equals 1.\n",
      "    \"\"\"\n",
      "    norm = integrate_over_grid(grid_steps, ppd)\n",
      "    return norm, ppd / norm \n",
      "\n",
      "\n",
      "def ppd_mean(ppd, grid, grid_steps):\n",
      "    \"\"\"\n",
      "    Compute the mean of the PPD.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    ppd : array_like\n",
      "        the sampled (and normalized) PPD\n",
      "    grid : array_like\n",
      "        grid coordinates, as returned by\n",
      "        :func:`create_regular_grid`\n",
      "    grid_steps : 1-d array_like\n",
      "        the resolution (step length) of each\n",
      "        dimension of the regular grid\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    1-d array_like\n",
      "        mean values for each parameter\n",
      "    \n",
      "    \"\"\"\n",
      "    ppd_mean = [integrate_over_grid(grid_steps, ppd * grid[dim])\n",
      "                for dim in range(len(grid))]\n",
      "    \n",
      "    return np.array(ppd_mean)\n",
      "\n",
      "\n",
      "def ppd_covmat(ppd, grid, grid_steps):\n",
      "    \"\"\"\n",
      "    Compute the covariance matrix of PPD.\n",
      "    \n",
      "    \"\"\"\n",
      "    dimensions = range(len(grid))\n",
      "    \n",
      "    ppd_mean = compute_ppd_mean(ppd, grid, grid_steps)\n",
      "    \n",
      "    CM = [[integrate_over_grid(grid_steps, ppd *\n",
      "                               grid[idim] * grid[jdim])\n",
      "           - ppd_mean[idim] * ppd_mean[jdim]\n",
      "           for jdim in dimensions]\n",
      "          for idim in dimensions]\n",
      "    \n",
      "    return np.array(CM)\n",
      "\n",
      "\n",
      "def ppd_corrmat(covmat):\n",
      "    \"\"\"\n",
      "    Compute the correlation matrix given\n",
      "    the covariance matrix `covmat`.\n",
      "    \"\"\"\n",
      "    CrM = [[covmat[i][j] / np.sqrt(covmat[i][i] * covmat[j][j])\n",
      "            for j in range(covmat.shape[1])]\n",
      "           for i in range(covmat.shape[0])]\n",
      "    \n",
      "    return np.array(CrM)\n",
      "\n",
      "\n",
      "def marginal_ppd(ppd, grid_steps, *dims):\n",
      "    \"\"\"\n",
      "    Compute the (joint) marginal PPD for one or\n",
      "    more parameters.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    ppd : n-d array_like\n",
      "        the sampled (and normalized) PPD\n",
      "    grid_steps : 1-d array_like\n",
      "        the resolution (step length) of each\n",
      "        dimension of the regular grid\n",
      "    *dims : int, int, ...\n",
      "        parameters (grid dimensions) for which\n",
      "        to compute the (joint) marginal PPD\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    1-d or n-d array\n",
      "        values of the (joint) marginal PPD\n",
      "        on the regular grid. The number of\n",
      "        dimensions depends on the number\n",
      "        of `*dims` arguments given.\n",
      "    \"\"\"\n",
      "    M = ppd.copy()\n",
      "    ax = 0\n",
      "    \n",
      "    for d in range(len(grid_steps)):\n",
      "        if d in dims:\n",
      "            ax += 1\n",
      "            continue\n",
      "        M = integrate_over_grid(grid_steps[d], M, axis=ax)\n",
      "    \n",
      "    return M\n",
      "\n",
      "\n",
      "def profile_likelihood(likelihood, *dims):\n",
      "    \"\"\"\n",
      "    Compute the profile (log)likelihood for\n",
      "    one or more parameters\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    likelihood : n-d array_like\n",
      "        (log)likelihood\n",
      "    grid_steps : 1-d array_like\n",
      "        the resolution (step length) of each\n",
      "        dimension of the regular grid\n",
      "    *dims : int, int, ...\n",
      "        parameters (grid dimensions) for which\n",
      "        to compute the profile (log)likelihood\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    1-d or n-d array\n",
      "        values of the profile (log)likelihood\n",
      "        on the regular grid. The number of\n",
      "        dimensions depends on the number\n",
      "        of `*dims` arguments given.\n",
      "    \"\"\"\n",
      "    Lp = likelihood.copy()\n",
      "    ax = 0\n",
      "    \n",
      "    for d in range(likelihood.ndim):\n",
      "        if d in dims:\n",
      "            ax += 1\n",
      "            continue\n",
      "        Lp = Lp.max(axis=ax)\n",
      "    \n",
      "    return Lp\n",
      "\n",
      "\n",
      "def profile_likelihood_crit(profile_likelihood,\n",
      "                            max_likelihood,\n",
      "                            clevels=[0.674, 0.95, 0.997],\n",
      "                            log=True):\n",
      "    \"\"\"\n",
      "    Return the critical values of the profile\n",
      "    likelihood that correspond to the given confidence\n",
      "    levels (based on the likelihood ratio test).\n",
      "    \n",
      "    Useful for the calculation of confidence intervals.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    profile_likelihood : n-d array_like\n",
      "        the profile (log)likelihood\n",
      "    max_likelihood : float\n",
      "        maximized value of the (log) likelihood\n",
      "    clevels : list\n",
      "        confidence levels\n",
      "    log : bool\n",
      "        must be True if log-likelihoods are\n",
      "        provided\n",
      "        \n",
      "    \"\"\"\n",
      "    df = profile_likelihood.ndim\n",
      "    lambda_crit = [stats.chi2(df).ppf(cl)\n",
      "                   for cl in clevels]\n",
      "    ploglike_crit = (2. * max_likelihood - lambda_crit) / 2.\n",
      "    \n",
      "    if log:\n",
      "        return ploglike_crit\n",
      "    else:\n",
      "        return np.exp(ploglike_crit)\n",
      "\n",
      "\n",
      "class CosmogenicInferenceGC():\n",
      "    \"\"\"\n",
      "    Infer a set of parameters from measured cosmogenic\n",
      "    profile(s) using either MLE or Bayesian inference\n",
      "    with the grid search sampling method.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    description : string\n",
      "        brief description \n",
      "    \n",
      "    \"\"\"\n",
      "    def __init__(self, description=''):\n",
      "        \n",
      "        self.description = description\n",
      "        self.oprofile = dict()\n",
      "        self.parameters = OrderedDict()\n",
      "        self.grid = None\n",
      "        self.grid_size = None\n",
      "        self.grid_steps = None\n",
      "        self.mprofiles = None\n",
      "        self.chisq = None\n",
      "        self.likelihood = None\n",
      "        self.loglike = None\n",
      "        self.maxlike = None\n",
      "        self.mle = None\n",
      "        self.ppd = None\n",
      "        self.ppd_norm = None\n",
      "        self.ppd_mean = None\n",
      "        self.ppd_mean_f = None\n",
      "        self.ppd_max = None\n",
      "        self.ppd_max_i = None\n",
      "        self.ppd_max_f = None\n",
      "        self.ppd_covmat = None\n",
      "        self.ppd_corrmat = None\n",
      "        self.M_ppds_1d = None\n",
      "    \n",
      "    def set_profile_measured(self, depth, C, std, nucleide,\n",
      "                             **kwargs):\n",
      "        \"\"\"\n",
      "        Set the measured nucleide concentration profile.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        depth : 1-d array_like\n",
      "            the depth values\n",
      "        C : 1-d array_like\n",
      "            the measured nucleide concentration\n",
      "            values\n",
      "        std : 1-d array_like\n",
      "            the standard deviation of the measured\n",
      "            concentrations\n",
      "        nucleide : 1-d array_like\n",
      "            allow to distinguish concatenated profiles\n",
      "            of multiple nucleides\n",
      "        **kwargs : name=value, name=value...\n",
      "            any other information to provide about\n",
      "            the profile\n",
      "        \n",
      "        \"\"\"\n",
      "        self.oprofile['depth'] = np.array(depth)\n",
      "        self.oprofile['C'] = np.array(C)\n",
      "        self.oprofile['std'] = np.array(std)\n",
      "        self.oprofile['nucleide'] = np.array(nucleide)\n",
      "        self.oprofile.update(kwargs)\n",
      "        \n",
      "    def set_profile_model(self, func):\n",
      "        \"\"\"\n",
      "        Set the mathematical model for predicting\n",
      "        the comsogenic concentration profiles.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        func : callable\n",
      "            must accept depth values as the first\n",
      "            argument and parameter value(s) as the\n",
      "            other arguments for each parameter to fit,\n",
      "            defined in the SAME ORDER than\n",
      "            :attr:`CosmogenicProfileBayesGC.parameters` !\n",
      "        \n",
      "        \"\"\"\n",
      "        self.profile_model = func\n",
      "\n",
      "    def set_parameter(self, name, srange, prior=None,\n",
      "                      **kwargs):\n",
      "        \"\"\"\n",
      "        Set a model parameter to fit.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        name : string\n",
      "            name of the parameter\n",
      "        srange : (start, stop, step)\n",
      "            parameter search range used to compute\n",
      "            the sampling regular grid. if a complex\n",
      "            number is given for `step`, its real part\n",
      "            will be the number of samples to generate\n",
      "            instead of a step length.\n",
      "        prior : callable\n",
      "            the prior density probability function\n",
      "            for the parameter (must accept a 1-d\n",
      "            array_like as unique argument)\n",
      "        **kwargs : name=value, name=value...\n",
      "            any other information to provide about\n",
      "            the parameter\n",
      "        \n",
      "        \"\"\"\n",
      "        p = dict()\n",
      "        p['range'] = srange\n",
      "        p['prior'] = prior\n",
      "        p.update(kwargs)\n",
      "        self.parameters[name] = p\n",
      "    \n",
      "    @property\n",
      "    def deg_freedom(self):\n",
      "        try:\n",
      "            return self.oprofile['C'].size - len(self.parameters)\n",
      "        except Exception:\n",
      "            return None\n",
      "\n",
      "    def _set_sampling_grid(self):\n",
      "        \"\"\"\n",
      "        Create the sampling regular grid.\n",
      "        \"\"\"\n",
      "        ranges = [p['range'] for p in self.parameters.values()]\n",
      "        \n",
      "        self.grid = create_regular_grid(*ranges)\n",
      "        self.grid_sizes = [a.size for a in self.grid]\n",
      "        self.grid_total_size = np.prod(self.grid_sizes)\n",
      "\n",
      "        self.grid_steps = [1. * (stop - start) / step\n",
      "                           if isinstance(step, complex)\n",
      "                           else step\n",
      "                           for start, stop, step in ranges]\n",
      "    \n",
      "    def compute_mprofiles(self):\n",
      "        \"\"\"\n",
      "        Calculate the predicted nucleide concentration\n",
      "        vs. depth profiles at every node of the\n",
      "        sampling grid.\n",
      "        \"\"\"\n",
      "        if self.grid is None:\n",
      "            self._set_sampling_grid()\n",
      "            \n",
      "        # array broadcasting...\n",
      "        depth = self.oprofile['depth'].copy()\n",
      "        for dim in range(len(self.grid)):\n",
      "            depth = np.expand_dims(depth, axis=-1)\n",
      "        grid = [np.expand_dims(p, axis=0) for p in self.grid]\n",
      "        \n",
      "        self.mprofiles = self.profile_model(depth, *grid)\n",
      "    \n",
      "    def compute_like(self, f='loglike'):\n",
      "        \"\"\"\n",
      "        Calculate the loglikelihood (`f`='loglike'),\n",
      "        likelihood (`f`='likelihood') or chi-square\n",
      "        (`f`='chisq') values at every node\n",
      "        of the sampling grid.\n",
      "        \"\"\"\n",
      "        oprofile = self.oprofile['C'].copy()\n",
      "        ostd = self.oprofile['std'].copy()\n",
      "        \n",
      "        for dim in range(len(self.grid)):\n",
      "            oprofile = np.expand_dims(oprofile, axis=-1)\n",
      "            ostd = np.expand_dims(ostd, axis=-1)\n",
      "        \n",
      "        if f == 'loglike':\n",
      "            self.likelihood = likelihood(self.mprofiles,\n",
      "                                         oprofile, ostd)\n",
      "        elif f == 'likelihood':\n",
      "            self.likelihood = likelihood(self.mprofiles,\n",
      "                                         oprofile, ostd,\n",
      "                                         log=False)\n",
      "        elif f == 'chisq':\n",
      "            self.chisq = chi2(self.mprofile,\n",
      "                              oprofile, ostd) \n",
      "    \n",
      "    def compute_from_data_model(self, data_model):\n",
      "        \"\"\"\n",
      "        Get modelled profiles, chi2_r, likelihood, prior\n",
      "        and ppd from the given `data_model`.\n",
      "        \n",
      "        Returns a dictionary with the computed values.\n",
      "        \n",
      "        \"\"\"\n",
      "        f_names = ['mprofile', 'chisq', 'chisq_r', 'loglike',\n",
      "                   'prior', 'ppd']\n",
      "        \n",
      "        mprofile = self.profile_model(self.oprofile['depth'],\n",
      "                                      *data_model)\n",
      "\n",
      "        chisq = chi2(mprofile, self.oprofile['C'],\n",
      "                     self.oprofile['std'])\n",
      "        chisq_r = chisq / self.deg_freedom\n",
      "        \n",
      "        loglike = likelihood(mprofile, self.oprofile['C'],\n",
      "                             self.oprofile['std'])\n",
      "        \n",
      "        prior_funcs = [p['prior'] for p in self.parameters.values()]\n",
      "        prior = np.prod([pf(dm)\n",
      "                         for pf, dm in zip(prior_funcs, data_model)])\n",
      "\n",
      "        ppd = compute_ppd(prior, math.exp(loglike))\n",
      "        ppd /= self.ppd_norm\n",
      "        \n",
      "        results = dict(\n",
      "            zip(f_names, [mprofile, chisq, chisq_r,\n",
      "                          loglike, prior, ppd])\n",
      "        )\n",
      "        \n",
      "        return results\n",
      "    \n",
      "    \n",
      "    def compute_mle(self, log=True,\n",
      "                    save_mprofiles=False,\n",
      "                    save_likelihood=False):\n",
      "        \"\"\"\n",
      "        Compute the (log)likelihood, find its\n",
      "        maximum, and compute 1d and 2d profile\n",
      "        (log)likelihoods.\n",
      "        \"\"\"\n",
      "        \n",
      "        # compute (log)likelihood\n",
      "        self.compute_mprofiles()\n",
      "        \n",
      "        if log:\n",
      "            f = 'loglike'\n",
      "        else:\n",
      "            f = 'likelihood'\n",
      "        self.compute_like(f=f)\n",
      "        \n",
      "        # find maximum\n",
      "        self.maxlike = self.likelihood.max()\n",
      "        \n",
      "        mle_ind = np.nonzero(self.likelihood >= self.maxlike)\n",
      "        self.mle = [p.flatten()[mi]\n",
      "                    for p, mi in zip(self.grid, mle_ind)]\n",
      "        \n",
      "        # profile likelihoods\n",
      "        self.proflike1d = [profile_likelihood(self.likelihood,\n",
      "                                              dim)\n",
      "                           for dim in range(len(self.grid))]\n",
      "        \n",
      "        self.proflike2d = [[profile_likelihood(self.likelihood,\n",
      "                                               idim, jdim)\n",
      "                            for jdim in range(len(self.grid))]\n",
      "                           for idim in range(len(self.grid))]\n",
      "        \n",
      "        # keep or delete intermediate results\n",
      "        if not save_mprofiles:\n",
      "            self.mprofiles = None\n",
      "        if not save_likelihood:\n",
      "            self.likelihood = None \n",
      "        \n",
      "    \n",
      "    def compute_bayes(self, save_mprofiles=False,\n",
      "                      save_likelihood=False):\n",
      "        \"\"\"\n",
      "        Compute the normalized PPD, its mean,\n",
      "        its covariance matrix and all the 1-d and\n",
      "        2-d marginal PPDs (may take a while to compute\n",
      "        and may consume a lot of memory, depending\n",
      "        on the size of the sampling grid!!).\n",
      "        \n",
      "        The specified keyword arguments can be used to save\n",
      "        the intermediate results in the corresponding\n",
      "        attributes\n",
      "        \"\"\" \n",
      "        # compute the prior distribution \n",
      "        prior_funcs = [p['prior'] for p in self.parameters.values()]\n",
      "        prior = np.prod([pf(pg) for pf, pg in zip(prior_funcs, self.grid)],\n",
      "                        axis=0)\n",
      "        \n",
      "        # compute the likelihood function\n",
      "        self.compute_mprofiles()\n",
      "        self.compute_like(f='likelihood')\n",
      "        \n",
      "        # compute and normalize the PPD\n",
      "        ppd = ppd(self.likelihood, prior)\n",
      "        self.ppd_norm, self.ppd = normalize_ppd(ppd, self.grid_steps)\n",
      "        \n",
      "        # keep or delete intermediate results\n",
      "        if not save_mprofiles:\n",
      "            self.mprofiles = None\n",
      "        if not save_likelihood:\n",
      "            self.likelihood = None\n",
      "        \n",
      "        del ppd\n",
      "        del grid\n",
      "        \n",
      "        # compute PPD mean and mode (+ functions values)\n",
      "        self.ppd_mean = ppd_mean(self.ppd, self.grid,\n",
      "                                 self.grid_steps)\n",
      "        \n",
      "        self.ppd_mean_f = self.compute_from_data_model(self.ppd_mean)\n",
      "        \n",
      "        self.ppd_max_i = np.nonzero(self.ppd >= self.ppd.max())\n",
      "        self.ppd_max = [p.flatten()[mi]\n",
      "                        for p, mi in zip(self.grid,\n",
      "                                         self.ppd_max_i)]\n",
      "\n",
      "        self.ppd_max_f = self.compute_from_data_model(self.ppd_max)\n",
      "        \n",
      "        # compute PPD covavriance and correlation matrices\n",
      "        self.ppd_covmat = ppd_covmat(self.ppd,\n",
      "                                     self.grid,\n",
      "                                     self.grid_steps)\n",
      "        \n",
      "        self.ppd_corrmat = corrmat(self.ppd_covmat)\n",
      "        \n",
      "        \n",
      "        # compute 1D marginal PPDs and find maximums\n",
      "        self.M_ppds_1d = [marginal_ppd(self.ppd,\n",
      "                                       self.grid_steps,\n",
      "                                       dim)\n",
      "                          for dim in range(len(self.grid))]\n",
      "        \n",
      "        M_ppds_1d_max_i = [M.argmax()\n",
      "                           for M in self.M_ppds_1d]\n",
      "        self.M_ppds_1d_max = [p.flatten()[mi]\n",
      "                              for p, mi in zip(self.grid,\n",
      "                                               M_ppds_1d_max_i)]\n",
      "        \n",
      "        self.M_ppds_1d_max_f = self.compute_from_data_model(\n",
      "            self.M_ppds_1d_max\n",
      "        )\n",
      "        \n",
      "        # compute 2D marginal PPDs\n",
      "        self.M_ppds_2d = [[marginal_ppd(self.ppd,\n",
      "                                        self.grid_steps,\n",
      "                                        idim, jdim)\n",
      "                           for jdim in range(len(self.grid))]\n",
      "                          for idim in range(len(self.grid))]\n",
      "    \n",
      "    \n",
      "    def setup_summary(self):\n",
      "        if self.grid is None:\n",
      "            self._set_sampling_grid()\n",
      "        \n",
      "        summary = \"Modelling C profile (Bayes, Grid-Search)\\n\\n\"\n",
      "        summary += \"DESCRIPTION:\\n{desc}\\n\\n\".format(\n",
      "                       desc=self.description\n",
      "                   )\n",
      "        summary += \"MEASURED PROFILE ({N} samples):\\n\".format(\n",
      "                       N=len(self.oprofile['C'])\n",
      "                   )\n",
      "        summary += str(pd.DataFrame(self.oprofile))\n",
      "        summary += \"\\n\\n\"\n",
      "        summary += \"PROFILE MODEL:\\n{fname}\\n{fdoc}\\n\\n\".format(\n",
      "                       fname=self.profile_model.__name__,\n",
      "                       fdoc=inspect.getdoc(self.profile_model)\n",
      "                   )\n",
      "        summary += \"'UNKNOWN' PARAMETERS ({n}):\\n\".format(\n",
      "                       n=len(self.parameters)\n",
      "                   )\n",
      "        summary += \"\\n\".join([\n",
      "                       name + \":\\n\" +\n",
      "                       \"\\n\".join([\"\\t{0}: {1}\".format(k, v)\n",
      "                                  for k, v in p.items()])\n",
      "                        for name, p in self.parameters.items()\n",
      "                   ])\n",
      "        summary += \"\\n\\ndegrees of freedom: {dof}\\n\\n\".format(\n",
      "                       dof=self.deg_freedom\n",
      "                   )\n",
      "        summary += \"GRID SEARCH:\\n\"\n",
      "        summary += \"nb. of nodes per parameter: {np}\\n\".format(\n",
      "                       np=self.grid_sizes\n",
      "                   )\n",
      "        summary += \"total nb. of nodes: {ng}\\n\\n\".format(\n",
      "                       ng=self.grid_total_size\n",
      "                   )\n",
      "        \n",
      "        return summary\n",
      "    \n",
      "    def results_summary(self):\n",
      "        summary = \"RESULTS:\\n\\n\"\n",
      "        \n",
      "        if self.ppd is None:\n",
      "            return summary + \"no result yet\"\n",
      "        \n",
      "        summary += \"parameter names in order:\\n{0}\\n\\n\".format(\n",
      "                       self.parameters.keys()\n",
      "                   )\n",
      "        summary += \"PPD max:\\n{0}\\n\\n\".format(self.ppd_max)\n",
      "        summary += \"Values at PPD max:\\n\"\n",
      "        summary += \"\\n\".join([\"{0}:\\n {1}\".format(k, v)\n",
      "                              for k, v in self.ppd_max_f.items()])\n",
      "        summary += \"\\n\\n\"\n",
      "        summary += \"PPD mean:\\n{0}\\n\\n\".format(self.ppd_mean)\n",
      "        summary += \"Values at PPD mean:\\n\"\n",
      "        summary += \"\\n\".join([\"{0}:\\n {1}\".format(k, v)\n",
      "                              for k, v in self.ppd_mean_f.items()])\n",
      "        summary += \"\\n\\n\"\n",
      "        summary += \"1D Marginal PPD maxs:\\n{0}\\n\\n\".format(\n",
      "                        self.M_ppds_1d_max\n",
      "                   )\n",
      "        summary += \"Values at 1D Marginal PPD maxs:\\n\"\n",
      "        summary += \"\\n\".join([\"{0}:\\n {1}\".format(k, v)\n",
      "                              for k, v in self.M_ppds_1d_max_f.items()])\n",
      "        summary += \"\\n\\n\"\n",
      "        summary += \"PPD covmat:\\n{0}\\n\\n\".format(self.ppd_covmat)\n",
      "        summary += \"PPD corrmat:\\n{0}\\n\\n\".format(self.ppd_corrmat)\n",
      "        \n",
      "        return summary\n",
      "    \n",
      "    def __str__(self):\n",
      "        return self.setup_summary() + self.results_summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting gridsearch.py\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}